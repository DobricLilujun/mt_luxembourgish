{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import get_dataset_config_names\n",
    "import pandas as pd\n",
    "# Load the FLORES-200 dataset for a specific language pair\n",
    "dataset = load_dataset(\"facebook/flores\", \"eng_Latn-fra_Latn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/snt/.cache/huggingface/modules/datasets_modules/datasets/facebook--flores/2a1174c8c4991ca09a9cb5b9a367cb2e049b073852cb4097456164d4612391ef (last modified on Mon Dec 23 13:52:01 2024) since it couldn't be found locally at facebook/flores, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facebook/flores contains 41617 language pairs\n"
     ]
    }
   ],
   "source": [
    "flores_configs = get_dataset_config_names(\"facebook/flores\",\"all\")\n",
    "print(f\"facebook/flores contains {len(flores_configs)} language pairs\")\n",
    "\n",
    "# Filter out the non-English to English language pairs\n",
    "flores_configs_non_english_to_english = [\n",
    "    pair for pair in flores_configs \n",
    "    if pair.endswith(\"-eng_Latn\") and not pair.startswith(\"eng_Latn-\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_to_full_name_df = pd.read_csv(\"results_translator - language pair.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ace_Arab-eng_Latn\n",
      "Processing ace_Latn-eng_Latn\n",
      "Processing acm_Arab-eng_Latn\n",
      "Processing acq_Arab-eng_Latn\n",
      "Processing aeb_Arab-eng_Latn\n",
      "Processing afr_Latn-eng_Latn\n",
      "Processing ajp_Arab-eng_Latn\n",
      "Processing aka_Latn-eng_Latn\n",
      "Processing als_Latn-eng_Latn\n",
      "Processing amh_Ethi-eng_Latn\n",
      "Processing apc_Arab-eng_Latn\n",
      "Processing arb_Arab-eng_Latn\n",
      "Processing arb_Latn-eng_Latn\n",
      "Processing ars_Arab-eng_Latn\n",
      "Processing ary_Arab-eng_Latn\n",
      "Processing arz_Arab-eng_Latn\n",
      "Processing asm_Beng-eng_Latn\n",
      "Processing ast_Latn-eng_Latn\n",
      "Processing awa_Deva-eng_Latn\n",
      "Processing ayr_Latn-eng_Latn\n",
      "Processing azb_Arab-eng_Latn\n",
      "Processing azj_Latn-eng_Latn\n",
      "Processing bak_Cyrl-eng_Latn\n",
      "Processing bam_Latn-eng_Latn\n",
      "Processing ban_Latn-eng_Latn\n",
      "Processing bel_Cyrl-eng_Latn\n",
      "Processing bem_Latn-eng_Latn\n",
      "Processing ben_Beng-eng_Latn\n",
      "Processing bho_Deva-eng_Latn\n",
      "Processing bjn_Arab-eng_Latn\n",
      "Processing bjn_Latn-eng_Latn\n",
      "Processing bod_Tibt-eng_Latn\n",
      "Processing bos_Latn-eng_Latn\n",
      "Processing bug_Latn-eng_Latn\n",
      "Processing bul_Cyrl-eng_Latn\n",
      "Processing cat_Latn-eng_Latn\n",
      "Processing ceb_Latn-eng_Latn\n",
      "Processing ces_Latn-eng_Latn\n",
      "Processing cjk_Latn-eng_Latn\n",
      "Processing ckb_Arab-eng_Latn\n",
      "Processing crh_Latn-eng_Latn\n",
      "Processing cym_Latn-eng_Latn\n",
      "Processing dan_Latn-eng_Latn\n",
      "Processing deu_Latn-eng_Latn\n",
      "Processing dik_Latn-eng_Latn\n",
      "Processing dyu_Latn-eng_Latn\n",
      "Processing dzo_Tibt-eng_Latn\n",
      "Processing ell_Grek-eng_Latn\n",
      "Processing epo_Latn-eng_Latn\n",
      "Processing est_Latn-eng_Latn\n",
      "Processing eus_Latn-eng_Latn\n",
      "Processing ewe_Latn-eng_Latn\n",
      "Processing fao_Latn-eng_Latn\n",
      "Processing fij_Latn-eng_Latn\n",
      "Processing fin_Latn-eng_Latn\n",
      "Processing fon_Latn-eng_Latn\n",
      "Processing fra_Latn-eng_Latn\n",
      "Processing fur_Latn-eng_Latn\n",
      "Processing fuv_Latn-eng_Latn\n",
      "Processing gaz_Latn-eng_Latn\n",
      "Processing gla_Latn-eng_Latn\n",
      "Processing gle_Latn-eng_Latn\n",
      "Processing glg_Latn-eng_Latn\n",
      "Processing grn_Latn-eng_Latn\n",
      "Processing guj_Gujr-eng_Latn\n",
      "Processing hat_Latn-eng_Latn\n",
      "Processing hau_Latn-eng_Latn\n",
      "Processing heb_Hebr-eng_Latn\n",
      "Processing hin_Deva-eng_Latn\n",
      "Processing hne_Deva-eng_Latn\n",
      "Processing hrv_Latn-eng_Latn\n",
      "Processing hun_Latn-eng_Latn\n",
      "Processing hye_Armn-eng_Latn\n",
      "Processing ibo_Latn-eng_Latn\n",
      "Processing ilo_Latn-eng_Latn\n",
      "Processing ind_Latn-eng_Latn\n",
      "Processing isl_Latn-eng_Latn\n",
      "Processing ita_Latn-eng_Latn\n",
      "Processing jav_Latn-eng_Latn\n",
      "Processing jpn_Jpan-eng_Latn\n",
      "Processing kab_Latn-eng_Latn\n",
      "Processing kac_Latn-eng_Latn\n",
      "Processing kam_Latn-eng_Latn\n",
      "Processing kan_Knda-eng_Latn\n",
      "Processing kas_Arab-eng_Latn\n",
      "Processing kas_Deva-eng_Latn\n",
      "Processing kat_Geor-eng_Latn\n",
      "Processing kaz_Cyrl-eng_Latn\n",
      "Processing kbp_Latn-eng_Latn\n",
      "Processing kea_Latn-eng_Latn\n",
      "Processing khk_Cyrl-eng_Latn\n",
      "Processing khm_Khmr-eng_Latn\n",
      "Processing kik_Latn-eng_Latn\n",
      "Processing kin_Latn-eng_Latn\n",
      "Processing kir_Cyrl-eng_Latn\n",
      "Processing kmb_Latn-eng_Latn\n",
      "Processing kmr_Latn-eng_Latn\n",
      "Processing knc_Arab-eng_Latn\n",
      "Processing knc_Latn-eng_Latn\n",
      "Processing kon_Latn-eng_Latn\n",
      "Processing kor_Hang-eng_Latn\n",
      "Processing lao_Laoo-eng_Latn\n",
      "Processing lij_Latn-eng_Latn\n",
      "Processing lim_Latn-eng_Latn\n",
      "Processing lin_Latn-eng_Latn\n",
      "Processing lit_Latn-eng_Latn\n",
      "Processing lmo_Latn-eng_Latn\n",
      "Processing ltg_Latn-eng_Latn\n",
      "Processing ltz_Latn-eng_Latn\n",
      "Processing lua_Latn-eng_Latn\n",
      "Processing lug_Latn-eng_Latn\n",
      "Processing luo_Latn-eng_Latn\n",
      "Processing lus_Latn-eng_Latn\n",
      "Processing lvs_Latn-eng_Latn\n",
      "Processing mag_Deva-eng_Latn\n",
      "Processing mai_Deva-eng_Latn\n",
      "Processing mal_Mlym-eng_Latn\n",
      "Processing mar_Deva-eng_Latn\n",
      "Processing min_Arab-eng_Latn\n",
      "Processing min_Latn-eng_Latn\n",
      "Processing mkd_Cyrl-eng_Latn\n",
      "Processing mlt_Latn-eng_Latn\n",
      "Processing mni_Beng-eng_Latn\n",
      "Processing mos_Latn-eng_Latn\n",
      "Processing mri_Latn-eng_Latn\n",
      "Processing mya_Mymr-eng_Latn\n",
      "Processing nld_Latn-eng_Latn\n",
      "Processing nno_Latn-eng_Latn\n",
      "Processing nob_Latn-eng_Latn\n",
      "Processing npi_Deva-eng_Latn\n",
      "Processing nso_Latn-eng_Latn\n",
      "Processing nus_Latn-eng_Latn\n",
      "Processing nya_Latn-eng_Latn\n",
      "Processing oci_Latn-eng_Latn\n",
      "Processing ory_Orya-eng_Latn\n",
      "Processing pag_Latn-eng_Latn\n",
      "Processing pan_Guru-eng_Latn\n",
      "Processing pap_Latn-eng_Latn\n",
      "Processing pbt_Arab-eng_Latn\n",
      "Processing pes_Arab-eng_Latn\n",
      "Processing plt_Latn-eng_Latn\n",
      "Processing pol_Latn-eng_Latn\n",
      "Processing por_Latn-eng_Latn\n",
      "Processing prs_Arab-eng_Latn\n",
      "Processing quy_Latn-eng_Latn\n",
      "Processing ron_Latn-eng_Latn\n",
      "Processing run_Latn-eng_Latn\n",
      "Processing rus_Cyrl-eng_Latn\n",
      "Processing sag_Latn-eng_Latn\n",
      "Processing san_Deva-eng_Latn\n",
      "Processing sat_Olck-eng_Latn\n",
      "Processing scn_Latn-eng_Latn\n",
      "Processing shn_Mymr-eng_Latn\n",
      "Processing sin_Sinh-eng_Latn\n",
      "Processing slk_Latn-eng_Latn\n",
      "Processing slv_Latn-eng_Latn\n",
      "Processing smo_Latn-eng_Latn\n",
      "Processing sna_Latn-eng_Latn\n",
      "Processing snd_Arab-eng_Latn\n",
      "Processing som_Latn-eng_Latn\n",
      "Processing sot_Latn-eng_Latn\n",
      "Processing spa_Latn-eng_Latn\n",
      "Processing srd_Latn-eng_Latn\n",
      "Processing srp_Cyrl-eng_Latn\n",
      "Processing ssw_Latn-eng_Latn\n",
      "Processing sun_Latn-eng_Latn\n",
      "Processing swe_Latn-eng_Latn\n",
      "Processing swh_Latn-eng_Latn\n",
      "Processing szl_Latn-eng_Latn\n",
      "Processing tam_Taml-eng_Latn\n",
      "Processing taq_Latn-eng_Latn\n",
      "Processing taq_Tfng-eng_Latn\n",
      "Processing tat_Cyrl-eng_Latn\n",
      "Processing tel_Telu-eng_Latn\n",
      "Processing tgk_Cyrl-eng_Latn\n",
      "Processing tgl_Latn-eng_Latn\n",
      "Processing tha_Thai-eng_Latn\n",
      "Processing tir_Ethi-eng_Latn\n",
      "Processing tpi_Latn-eng_Latn\n",
      "Processing tsn_Latn-eng_Latn\n",
      "Processing tso_Latn-eng_Latn\n",
      "Processing tuk_Latn-eng_Latn\n",
      "Processing tum_Latn-eng_Latn\n",
      "Processing tur_Latn-eng_Latn\n",
      "Processing twi_Latn-eng_Latn\n",
      "Processing tzm_Tfng-eng_Latn\n",
      "Processing uig_Arab-eng_Latn\n",
      "Processing ukr_Cyrl-eng_Latn\n",
      "Processing umb_Latn-eng_Latn\n",
      "Processing urd_Arab-eng_Latn\n",
      "Processing uzn_Latn-eng_Latn\n",
      "Processing vec_Latn-eng_Latn\n",
      "Processing vie_Latn-eng_Latn\n",
      "Processing war_Latn-eng_Latn\n",
      "Processing wol_Latn-eng_Latn\n",
      "Processing xho_Latn-eng_Latn\n",
      "Processing ydd_Hebr-eng_Latn\n",
      "Processing yor_Latn-eng_Latn\n",
      "Processing yue_Hant-eng_Latn\n",
      "Processing zho_Hans-eng_Latn\n",
      "Processing zho_Hant-eng_Latn\n",
      "Processing zsm_Latn-eng_Latn\n",
      "Processing zul_Latn-eng_Latn\n"
     ]
    }
   ],
   "source": [
    "all_data = []\n",
    "for pair in flores_configs_non_english_to_english:\n",
    "    print (f\"Processing {pair}\")\n",
    "    dataset = load_dataset(\"facebook/flores\", pair, split=\"devtest\")\n",
    "    for item in dataset:\n",
    "        item[\"language_pair\"] = pair\n",
    "        \n",
    "        item['source_language'] = item['language_pair'].split('-')[0]\n",
    "        item['target_language'] = item['language_pair'].split('-')[1]\n",
    "\n",
    "        item['source_sentence'] = item[f\"sentence_{item['source_language']}\"]\n",
    "        item['target_sentence'] = item[f\"sentence_{item['target_language']}\"]\n",
    "\n",
    "        source_full_name = ab_to_full_name_df.loc[ab_to_full_name_df['Abreviation'] == item['source_language'], 'Full name'].values[0]\n",
    "        target_full_name = ab_to_full_name_df.loc[ab_to_full_name_df['Abreviation'] == item['target_language'], 'Full name'].values[0]\n",
    "\n",
    "        item['source_language_full_name'] = source_full_name\n",
    "        item['target_language_full_name'] = target_full_name\n",
    "\n",
    "        all_data.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_data)\n",
    "df = df[[\"id\",\"URL\",\"domain\",\"topic\",\"language_pair\",\"source_language\",\"target_language\",\"source_sentence\",\"target_sentence\",\"source_language_full_name\",\"target_language_full_name\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 205436/205436 [00:05<00:00, 34990.86it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "def generate_prompt(row):\n",
    "    return f\"\"\"You are a professional translator. Your task is to translate the following text from {row['source_language_full_name']} to {row['target_language_full_name']}. Provide only the translation without any additional explanation.\n",
    "\n",
    "{row['source_sentence']}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df['input'] = df.progress_apply(generate_prompt, axis=1)\n",
    "save_df = df.copy()\n",
    "save_df.reset_index(inplace=True, names=\"index\")\n",
    "columns_to_save = [\"index\",\"source_language_full_name\",\"target_language_full_name\",\"input\"]\n",
    "save_df = save_df[columns_to_save]\n",
    "save_df.to_json(\"data/flores-200-translation.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 205436/205436 [00:04<00:00, 44227.81it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "def generate_understanding_prompt(row):\n",
    "    return f\"\"\"You are a professional linguist. Your task is to understand and explain the meaning of the following text written in {row['source_language_full_name']}.\n",
    "\n",
    "{row['source_sentence']}\n",
    "\n",
    "### Explanation:\n",
    "Please explain the meaning of the text in your own words.\n",
    "\"\"\"\n",
    "\n",
    "df['input'] = df.progress_apply(generate_understanding_prompt, axis=1)\n",
    "save_df = df.copy()\n",
    "save_df.reset_index(inplace=True, names=\"index\")\n",
    "columns_to_save = [\"index\",\"source_language_full_name\",\"target_language_full_name\",\"input\"]\n",
    "save_df = save_df[columns_to_save]\n",
    "save_df.to_json(\"data/flores-200-explanation.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mt_lux_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
